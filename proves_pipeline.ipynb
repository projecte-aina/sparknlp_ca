{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "badc70b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "spark = sparknlp.start(spark32=True)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bac3afa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Spark NLP version:  3.4.2\n",
      "Apache Spark version:  3.2.0\n"
=======
      "Spark NLP version:  3.4.4\n",
      "Apache Spark version:  3.2.1\n"
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
     ]
    }
   ],
   "source": [
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c82d75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "284c2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    "      .setInputCol(\"text\")\\\n",
    "      .setOutputCol(\"document\")\\\n",
    "      .setCleanupMode(\"shrink_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18da27cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_detector_dl download started this may take some time.\n",
      "Approximate size to download 514.9 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "sentencerDL = SentenceDetectorDLModel\\\n",
    "  .pretrained(\"sentence_detector_dl\", \"xx\") \\\n",
    "  .setInputCols([\"document\"]) \\\n",
    "  .setOutputCol(\"sentence\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 9,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "cf8efd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = RoBertaEmbeddings.load(\"PlanTL-GOB-ES/roberta-base-ca_spark_nlp\")\\\n",
    "  .setInputCols([\"sentence\",'token'])\\\n",
    "  .setOutputCol(\"embeddings\")\\\n",
    "  .setCaseSensitive(True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 10,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "f551bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingsSentence = SentenceEmbeddings() \\\n",
    "    .setInputCols([\"sentence\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"sentence_embeddings\") \\\n",
    "    .setPoolingStrategy(\"AVERAGE\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 11,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "1bad442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingsFinisher = EmbeddingsFinisher() \\\n",
    "    .setInputCols([\"sentence_embeddings\"]) \\\n",
    "    .setOutputCols(\"finished_embeddings\") \\\n",
    "    .setOutputAsVector(True) \\\n",
    "    .setCleanAnnotations(False)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 12,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "7f72e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_list = [\"aprox.\",\"pàg.\",\"p.ex.\",\"gen.\",\"feb.\",\"abr.\",\"jul.\",\"set.\",\"oct.\",\"nov.\",\"des.\",\"dr.\",\"dra.\",\"sr.\",\"sra.\",\"srta.\",\"núm.\",\"st.\",\"sta.\",\"pl.\",\"etc.\", \"ex.\"]\n",
    "#,\"’\", '”', \"(\", \"[\", \"l'\",\"l’\",\"s'\",\"s’\",\"d’\",\"d'\",\"m’\",\"m'\",\"L'\",\"L’\",\"S’\",\"S'\",\"N’\",\"N'\",\"M’\",\"M'\"]\n",
    "ex_list_all = []\n",
    "ex_list_all.extend(ex_list)\n",
    "ex_list_all.extend([x[0].upper() + x[1:] for x in ex_list])\n",
    "ex_list_all.extend([x.upper() for x in ex_list])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 258,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "fcc50674",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols(['sentence']).setOutputCol('token') \\\n",
    "    .setContextChars(['.', ',', ';', ':', '!', '?', '*', '-', '(', ')', '\"', \"'\", \"«\", \"»\"]) \\\n",
    "    .setSuffixPattern(\"([A-zÀ-ú]*)(-la|-lo|-les|-los|-hi|-en|-ho|'n|'l|'ls|'m|'t|hi|ho|-LA|-LO|-LES|-LOS|-HI|-EN|-HO|'N|'L|'LS|'M|'T|HI|HO|)(.|,|;|:|!|\\?|\\)|\\\", »|)\\z\") \\\n",
    "    .setInfixPatterns([\"(\\\"|«|¿|\\(|^)(d'|l'|D'|L')([A-zÀ-ú]*)\", \"(\\\"|«|¿|\\(|^)(d|p|D|P)(el|els|EL|ELS)$\", \"(\\\"|«|¿|\\(|^)(a|A)(l|ls|L|LS)$\", \"([A-zÀ-ú]*)(-la|-lo|-les|-los|-nos|-vos|-te|-hi|-en|-ho|-n'|-l'|'ls|-m'|-t'|-hi|-ho|-LA|-LO|-LES|-LOS|-NOS|-VOS|-TE|-HI|-EN|-HO|-N'|-L'|'LS|-M'|-T'|-HI|-HO|)\"]) \\\n",
    "    .setExceptions(ex_list_all)#.fit(data)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 72,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "fb889c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"form\")\\\n",
    "    .setLowercase(True)\\\n",
    "    .setCleanupPatterns([\"\\n \"])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 15,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "3cad6202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords_iso download started this may take some time.\n",
      "Approximate size to download 2 KB\n",
      "[ | ]stopwords_iso download started this may take some time.\n",
      "Approximate size to download 2 KB\n",
<<<<<<< HEAD
      "[ — ]Download done! Loading the resource.\n",
=======
      "[ / ]Download done! Loading the resource.\n",
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "stop_words = StopWordsCleaner.pretrained(\"stopwords_iso\",\"ca\") \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"cleanTokens\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 16,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "c27a72eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = Lemmatizer() \\\n",
    "    .setInputCols([\"form\"]) \\\n",
    "    .setOutputCol(\"lemma\") \\\n",
    "    .setDictionary(\"ca_lemma_dict.tsv\", \"\\t\", \" \")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 17,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "a061b06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_ud_ancora download started this may take some time.\n",
      "Approximate size to download 2 MB\n",
      "[ | ]pos_ud_ancora download started this may take some time.\n",
      "Approximate size to download 2 MB\n",
<<<<<<< HEAD
      "Download done! Loading the resource.\n",
      "[ / ]"
=======
      "[ \\ ]Download done! Loading the resource.\n"
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
=======
      "\r",
      "[Stage 9:====================================================>    (11 + 1) / 12]\r",
      "\r",
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "pos = PerceptronModel.pretrained(\"pos_ud_ancora\", \"ca\") \\\n",
    "  .setInputCols([\"document\", \"token\"]) \\\n",
    "  .setOutputCol(\"pos\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 19,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "2cf523ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoBertaForTokenClassification_e660c813981d"
      ]
     },
<<<<<<< HEAD
     "execution_count": 17,
=======
     "execution_count": 19,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = RoBertaForTokenClassification.load(\"projecte-aina/roberta-base-ca-cased-ner_spark_nlp\")\n",
    "ner.setOutputCol('ner')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 20,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "a8945c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "nerconverter = NerConverter()\\\n",
    "    .setInputCols([\"document\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"entities\")#\\"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 284,
=======
   "execution_count": 353,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "225792ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = Chunker() \\\n",
    "   .setInputCols([\"sentence\", \"pos\"]) \\\n",
    "   .setOutputCol(\"chunk\") \\\n",
<<<<<<< HEAD
    "   .setRegexParsers([\"<DET>*<ADV>*<NUM>*<ADJ>*<NOUN>+<NUM>*<ADV>*<ADJ>*\", \"<DET>*<PROPN>+\", \"<DET>+<ADV>*<ADJ>+<ADV>*\", \"<PRON>\"])\n",
    "# \"<DET>*<ADV>*<NUM>*<ADJ>*(<ADJ>|<NOUN>)+<NOUN>*<NUM>*<ADV>*<ADJ>*\""
=======
    "   .setRegexParsers([\"<DET>*<ADV>*<ADJ>*<NOUN>+<ADV>*<ADJ>*\", \"<DET>*<PROPN>+\", \"<DET>+<ADV>*<ADJ>+<ADV>*\", \"<PRON>\"])"
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 285,
=======
   "execution_count": 354,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "9bfa8950",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpPipeline = Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    sentencerDL,\n",
    "    tokenizer,\n",
    "    normalizer,\n",
    "    stop_words,\n",
    "    embeddings,\n",
    "    embeddingsSentence,\n",
    "    embeddingsFinisher,\n",
    "    lemmatizer,\n",
    "    pos,\n",
    "    ner,\n",
    "    nerconverter,\n",
    "    chunker\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 286,
=======
   "execution_count": 355,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "a0efa67e",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "text = \"A partir d'aquest any, la incidència ha anat baixant, passant del 21,1 per cent l'any 1999 al 19,4 per cent de 2000.\"\n",
=======
    "text = \"Veig a l'home dels Estats Units amb el telescopi.\"\n",
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
    "spark_df = spark.createDataFrame([[text]]).toDF(\"text\")\n",
    "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
    "pipelineModel = nlpPipeline.fit(empty_df)\n",
    "result = pipelineModel.transform(spark_df)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 287,
=======
   "execution_count": 356,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "0751eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import LightPipeline\n",
    "light_model = LightPipeline(pipelineModel)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 288,
=======
   "execution_count": 357,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "613fc061",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "text = \"el cotxe vermell\""
=======
    "text = \"venien (del delta) a buscar l'aigua. anem-nos-en de la casa. ella.\""
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 289,
=======
   "execution_count": 358,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "9655a678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "     token    lemma   pos ner\n",
      "0       el       el   DET   O\n",
      "1    cotxe    cotxe  NOUN   O\n",
      "2  vermell  vermell   ADJ   O\n"
=======
      "     token   lemma    pos ner\n",
      "0   venien   venir   VERB   O\n",
      "1        (       (  PUNCT   O\n",
      "2        d      de   NOUN   O\n",
      "3       el      el    DET   O\n",
      "4    delta   delta   NOUN   O\n",
      "5        )       )  PUNCT   O\n",
      "6        a       a    ADP   O\n",
      "7   buscar  buscar   VERB   O\n",
      "8       l'      el    DET   O\n",
      "9    aigua   aigua   NOUN   O\n",
      "10       .       .  PUNCT   O\n",
      "11    anem    anar   VERB   O\n",
      "12    -nos     nos  PROPN   O\n",
      "13     -en     -en  PROPN   O\n",
      "14      de      de    ADP   O\n",
      "15      la      la    DET   O\n",
      "16    casa    casa   NOUN   O\n",
      "17       .       .  PUNCT   O\n",
      "18    ella     ell   PRON   O\n",
      "19       .       .  PUNCT   O\n"
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
     ]
    }
   ],
   "source": [
    "light_result = light_model.annotate(text)\n",
    "result = pd.DataFrame(zip(light_result['token'], light_result['lemma'], light_result['pos'], light_result['ner']), columns = [\"token\", \"lemma\", \"pos\", \"ner\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 290,
=======
   "execution_count": 339,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "2a1e4021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entites: []\n"
     ]
    }
   ],
   "source": [
    "print(\"entites:\", light_result['entities'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 291,
=======
   "execution_count": 359,
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "id": "c26658c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "chunk: ['el cotxe vermell']\n"
=======
      "chunk: ['d', 'el delta', \"l'aigua\", 'la casa', '-nos-en', 'ella']\n"
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
     ]
    }
   ],
   "source": [
    "print(\"chunk:\", light_result['chunk'])"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "raw",
   "id": "1c997874",
   "metadata": {},
   "source": [
    "problemes: \n",
    "    - al chunker: com expressar l'optativitat? (el nucli pot ser adj, o nom, o num)\n",
    "    - al tokenizer: sembla que hi ha un límit de caràcters en els infixos.\n",
    "    exemple: tokenitza correctament \"d'aquest,\", \"d'aquets,\" però no \"d'aquests\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c6ef49",
=======
   "cell_type": "code",
   "execution_count": null,
   "id": "7470041b",
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.8.13"
=======
   "version": "3.8.0"
>>>>>>> 39df5caf3969e75339eaf6f4dd2b617cff152eb6
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
